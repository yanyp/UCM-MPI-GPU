# Parallelizable Dense Labeling Framework for Very-High-Resolution Satellite Images

This is the implementation of the parallelizable semi-supervised dense labeling framework for Very-High-Resolution (VHR) Satellite Images. The main steps contain OWT-UCM superpixel segmentation and GLSVM semi-supervised classification as our [paper](https://www.cise.ufl.edu/~anand/pdf/IJBDI_anandlyx_webversion.pdf) describes. Only a limited number of expert-labeled points in terms of pixel coordinates are needed for the pixel-level labeling work on the whole image. A toy example of the parallel labeling pipeline is shown as below.

![Framework Example](https://https://github.com/yanyp/UCM-MPI-GPU/master/FrameworkExample.png "Framework Example")

The original [OWT-UCM](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html) algorithm is re-written in C++ and CUDA to support the parallelization operations. We refer to the UC Berkeley's image contour detection [paper](https://parlab.eecs.berkeley.edu/sites/all/parlab/files/iccv2009.pdf) and Bryan's [codes](https://github.com/bryancatanzaro/damascene) for the GPU acceleration. When NVIDIA GPUs are not available, we use the [Spectra](https://spectralib.org/) C++ library to solve the large-scale eigenvalue problem of the *sPb* computation. Note that our codes are still under revision based on Google C++ style [guide](https://google.github.io/styleguide/cppguide.html).

## Compilation

For this parallel framework, you need CMake (>= 2.8), GCC (>= 4.x), MPICH (= 3.x), OpenCV (= 2.x), [CUDA](https://developer.nvidia.com/cuda-downloads) (>= 7.5), and [ACML](http://developer.amd.com/tools-and-sdks/archive/acml-downloads-resources/) (>= 5.3).

CMake will detect all the libraries provided they are installed at their default paths. If not, you can use some of these CMake switches:

- ACML_INSTALL_DIR : ```cmake -DACML_INSTALL_DIR=$HOME/tech/acml5.3.1/gfortran64```
- MPI_INSTALL_DIR : ```cmake -DMPI_INSTALL_DIR=$HOME/tech/mpi```
- OPENCV_INSTALL_DIR : ```cmake -DOPENCV_INSTALL_DIR=$HOME/tech/opencv```
- CUDA_ARCH : ```cmake -DCUDA_ARCH=sm_35```

Run ```cmake .``` and ```make -j20``` (spawns 20 parallel jobs) to compile the source files.

## Execution

To run this framework, use ```mpirun -n 16 ./bin/ucm-mpi ./labeledData/example.jpg 3 16 1 0.07 6```. The description of the arguments is as follow:

- **-n 16** : use 16 MPI processes, denoted as ```kMpiProcess```.
- **./bin/ucm-mpi** : location of the executable file.
- **./labeledData/example.jpg** : location of the input image, the filename of which is ```example.jpg```.
- **3** : number of labeling categories in the set of expert-labeled points, denoted as ```kClasses```.
- **16** : number of the smaller patches, over which *gPb* of OWT-UCM is computed, denoted as ```kSmallerPatch```.
- **1** : number of the larger patches, over which the remaining steps of OWT-UCM and GLSVM are performed, denoted as ```kLargerPatch```.
- **0.07** : the fine level threshold of the OWT-UCM superpixel segmentation, denoted as ```kSmallThreshold```.
- **6** : seconds of the waiting time to wake up the sleeping MPI processes.

Note that both ```kSmallerPatch``` and ```kLargerPatch``` must be perfect square numbers. The relationship of these numbers is ```kLargerPatch``` ¡Ü ```kSmallerPatch``` = ```kMpiProcess```.


## Prerequisite Data

The input image must have an expert-labeled data file and a texton codebook file. Optionally, you can provide at most ```kClasses``` ground-truth map files, either of which has a matrix containing all the pixel labels of a specific category on the VHR image, so that you can evaluate the pixel-level misclassification error. Here are more details of the necessary input files:

- **Image** : The large-scale VHR image needs to be densely labeled. The common image formats (*JPEG*, *PNG*, *TIF*) are supported, such as ```<filename>.jpg```.

- **Expert-Labeled Points** : A text file consists of the rows in format of <```x,y,c```>, where ```x``` and ```y``` are the column and row coordinates of the expert-labeled points in the actual image, and ```c``` is the belonging terrain category. This file needs to be named as ```<filename>_GT.txt```.

- **Texton Codebook** : A 13 ¡Á 32 OpenCV matrix contains 32 representational [texton](http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html)  responses in 13 dimensions based on the *Schmid* filter bank. It can be externally generated by OpenCV or MATLAB. This file needs to be named as ```<filename>_texton_codebook.yml```.

- **Ground-truth Map** : An OpenCV matrix of the same dimensions as the actual image, filled with 0s (pixel does not belong to ```class_n```) and 1s (pixel belongs to ```class_n```). The files needs to be named as ```<filename>_labels_map_class_<class_n>.yml```.

A set of example input files is provided in the ```labeledData``` folder. Note that you also need to create a target folder of ```<filename>_<kSmallerPatch>_<kLargePatch>``` under this path before running your case.

## Output Results
The framework can output the full OWT-UCM segmentation result to:
- An image file of ```<filename>_<kSmallThreshold>_ucm.png``` plotting the edge contours
- A data file of ```<filename>_<kSmallThreshold>_ucm.yml``` storing the contour strength

Similarly, the GLSVM classification results are saved in:
- An image file of ```<filename>_<kSmallThreshold>_classlabels.png``` plotting the regions in different gray-scale colors (for different terrain categories)
- A data file of ```<filename>_<kSmallThreshold>_classlabels.yml``` storing the class labels

The pixel-level misclassification error will be printed at the end of the terminal output.